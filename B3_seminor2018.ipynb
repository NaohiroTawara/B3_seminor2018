{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B3_seminor2018.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "eSLcboA7fwOs",
        "-SqcmDc0fcu3",
        "JsY3qxxofhGF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaohiroTawara/B3_seminor2018/blob/master/B3_seminor2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MgNHooNSNV1i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Colaboratory（Google Colab）とは"
      ]
    },
    {
      "metadata": {
        "id": "ZHGxM1fRNNL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "・ Google Colabは、完全にクラウドで実行される Jupyter ノートブック環境です．\n",
        "\n",
        "・感覚的には，クラウド上のバーチャル環境を割り当てられ，無料で使えるイメージです"
      ]
    },
    {
      "metadata": {
        "id": "C9Ad6HEhZmv-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 注意事項\n",
        "\n",
        "\n",
        "\n",
        "### ９０分ルール，１２時間ルール\n",
        "\n",
        " \n",
        "*   計算途中でこのページを離れても計算は継続されますが，ページから離れたまま９０分が経過すると計算が強制的に止まります．そのため９０分以上かかる計算を行う場合はブラウザを閉じないようにしてください\n",
        "\n",
        "*   ページから離れるかにかかわらず，起動時から１２時間が経過するとすべての環境がリセットされます．そのため１２時間以上計算がかかる場合はこのスクリプトは適用できません．\n",
        "\n",
        "*   いずれの場合においても，一旦学習が完了したモデルはgoogle drive に自動的に保存されるため，環境リセット後も「初期設定」を実行すると即座に復元されます．\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "95FbEFpYN9mh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 使い方"
      ]
    },
    {
      "metadata": {
        "id": "m6PUwAFbOHq3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "挿入ー＞コードセルを選択するとコードを打ち込み，実行可能なセルが追加されます.\n",
        "\n",
        "コードセルはpython のコマンドの他に，!マークを先頭につけることで仮想環境のbashコマンドを実行することができます\n",
        "\n",
        "コマンド入力後にセルの左にある▶を押すとコードが実行されます\n"
      ]
    },
    {
      "metadata": {
        "id": "-T6iNY7xOOD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a=1\n",
        "b=2\n",
        "print(\"a + b = {}\".format(a+b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h19eAurvO5Pc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls # カレントディレクトリ内の一覧を見るコマンド"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niexkbOXO7lD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /etc/lsb-release #Linux のバージョンを調べるコマンド"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8JnwkMQPInn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!free -h # メモリを調べるコマンド"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ps7wvXtIPMVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo | grep -e \"model name\" -e \"processor\" #cpuの型番を調べるコマンド"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxWye7s8NEa1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GPUの割当"
      ]
    },
    {
      "metadata": {
        "id": "ADNmC9lnNZxA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ランタイムー＞ランタイムのタイプを変更\n",
        "\n",
        "ハードウェアアクセラレータをGPUに変更"
      ]
    },
    {
      "metadata": {
        "id": "tI_pWLIJPwwm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#matplotlibによる可視化の例"
      ]
    },
    {
      "metadata": {
        "id": "JaB2e1PMQEie",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.arange(20)\n",
        "y = [x_i + np.random.randn(1) for x_i in x]\n",
        "a, b = np.polyfit(x, y, 1)\n",
        "_ = plt.plot(x, y, 'o', np.arange(20), a*np.arange(20)+b, '-')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VobS2p59Wnlt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "-BeXhLf_Womb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# chainer によるDNN構築"
      ]
    },
    {
      "metadata": {
        "id": "xcO3TCGpWrGL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## chainer のインストール\n",
        "・chainerはデフォルトでは google colabで使えないので，仮想環境にインストールする必要があります "
      ]
    },
    {
      "metadata": {
        "id": "zf79Ykp_QE_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install https://github.com/kmaehashi/chainer-colab/releases/download/2018-02-06/cupy_cuda80-4.0.0b3-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install 'chainer==4.0.0b3'\n",
        "!apt-get install graphviz\n",
        "!pip install 'chaineripy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EgRklEXMXBi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "26dabf78-7b8d-4f27-fda1-78bfa2d86040"
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "#gpu が使えるかチェック\n",
        "print('GPU availability:', chainer.cuda.available)\n",
        "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU availability: True\n",
            "cuDNN availablility: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2unYeu8TXyEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST数字文字認識"
      ]
    },
    {
      "metadata": {
        "id": "cLqqh16lbn23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習データの用意"
      ]
    },
    {
      "metadata": {
        "id": "4nqv356Jbk28",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer.datasets import mnist\n",
        "# set matplotlib so that we can see our drawing inside this notebook\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download the MNIST data if you haven't downloaded it yet\n",
        "train, test = mnist.get_mnist(withlabel=True, ndim=1)\n",
        "# Display an example from the MNIST dataset.\n",
        "# `x` contains the input image array and `t` contains that target class\n",
        "# label as an integer.\n",
        "plt.figure()\n",
        "for i in range(1,11):\n",
        "  x, t = train[i]\n",
        "  plt.subplot(2,5,i)\n",
        "  plt.imshow(x.reshape(28, 28), cmap='gray')\n",
        "  plt.title('label: {}'.format(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHcPMXnLgPD2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 必要なパッケージのインポート"
      ]
    },
    {
      "metadata": {
        "id": "o57pg4ASgRN8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "from chainer.serializers import save_npz, load_npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zMd5ZeaJaYr2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ネットワーク構造の定義"
      ]
    },
    {
      "metadata": {
        "id": "37BSllOEXzbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network definition\n",
        "class MLP(chainer.Chain):\n",
        "\n",
        "    def __init__(self, n_units, n_out):\n",
        "        super(MLP, self).__init__()\n",
        "        with self.init_scope():\n",
        "            # the size of the inputs to each layer will be inferred\n",
        "            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n",
        "            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n",
        "            self.l3 = L.Linear(None, n_out)  # n_units -> n_out\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h1 = F.relu(self.l1(x))\n",
        "        h2 = F.relu(self.l2(h1))\n",
        "        return self.l3(h2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTirXJNoadOZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ネットワークの学習"
      ]
    },
    {
      "metadata": {
        "id": "vtjMh9heZBRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gpu = 0 #gpu id (CPUを使う場合は-1)\n",
        "unit = 100 # 中間層のノード数\n",
        "batchsize =128 # ミニバッチサイズ\n",
        "epoch =20 # エポック数\n",
        "out = 'results' # 結果の出力先\n",
        "frequency=-1 # 学習経過の出力タイミング -1の場合エポックごと\n",
        "    \n",
        "# Set up a neural network to train\n",
        "# Classifier reports softmax cross entropy loss and accuracy at every\n",
        "# iteration, which will be used by the PrintReport extension below.\n",
        "mlp = MLP(unit, 10)\n",
        "model = L.Classifier(mlp)\n",
        "if gpu >= 0:\n",
        "  # Make a specified GPU current\n",
        "  chainer.cuda.get_device_from_id(gpu).use()\n",
        "  model.to_gpu()  # GPU にコピー\n",
        "\n",
        "# 最適化法の選択\n",
        "optimizer = chainer.optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "# MNIST datasetの取得\n",
        "train, test = chainer.datasets.get_mnist()\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "test_iter = chainer.iterators.SerialIterator(test, batchsize,\n",
        "                                               repeat=False, shuffle=False)\n",
        "\n",
        "# Set up a trainer\n",
        "updater = training.StandardUpdater(train_iter, optimizer, device=gpu)\n",
        "trainer = training.Trainer(updater, (epoch, 'epoch'), out=out)\n",
        "\n",
        "# Evaluate the model with the test dataset for each epoch\n",
        "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu))\n",
        "\n",
        "# Dump a computational graph from 'loss' variable at the first iteration\n",
        "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
        "trainer.extend(extensions.dump_graph('main/loss'))\n",
        "\n",
        "# Take a snapshot for each specified epoch\n",
        "frequency = epoch if frequency == -1 else max(1, frequency)\n",
        "trainer.extend(extensions.snapshot(), trigger=(frequency, 'epoch'))\n",
        "\n",
        "# Write a log of evaluation statistics for each epoch\n",
        "trainer.extend(extensions.LogReport())\n",
        "\n",
        "# Save two plot images to the result dir\n",
        "if extensions.PlotReport.available():\n",
        "  trainer.extend(\n",
        "      extensions.PlotReport(['main/loss', 'validation/main/loss'],\n",
        "                            'epoch', file_name='loss.png'))\n",
        "  trainer.extend(\n",
        "      extensions.PlotReport(\n",
        "          ['main/accuracy', 'validation/main/accuracy'],\n",
        "          'epoch', file_name='accuracy.png'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch', 'main/loss', 'validation/main/loss',\n",
        "     'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
        "\n",
        "# Print a progress bar to stdout\n",
        "#trainer.extend(extensions.ProgressBar())\n",
        "\n",
        "# Run the training\n",
        "trainer.run()\n",
        "\n",
        "# Save the trained model\n",
        "save_npz(out+'/model', mlp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1ZYqSAbcjKT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習したモデルを用いてテストデータを識別してみる"
      ]
    },
    {
      "metadata": {
        "id": "ya2aHvxrYyBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the infrence (evaluation) model as the previous model\n",
        "infer_model = MLP(unit, 10)\n",
        "\n",
        "# Load the saved parameters into the parameters of the new inference model to overwrite \n",
        "load_npz(out+'/model', infer_model)\n",
        "\n",
        "# Send the model to utilize GPU by to_GPU\n",
        "if gpu >= 0:\n",
        "    infer_model.to_gpu(gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1vIKLRnccqLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get a test image and label\n",
        "x, t = test[0]\n",
        "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
        "plt.show()\n",
        "print('label:', t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I8PcTw38dB6R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6626f621-d000-4a25-965a-53ef802fa5d2"
      },
      "cell_type": "code",
      "source": [
        "# change the shape to minibutch. \n",
        "# In this example, the size of minibatch is 1. \n",
        "# Inference using any mini-batch size can be performed.\n",
        "\n",
        "print(x.shape, end=' -> ')\n",
        "x = x[None, ...]\n",
        "print(x.shape)\n",
        "\n",
        "# to calculate by GPU, send the data to GPU, too. \n",
        "if gpu >= 0:\n",
        "    x = chainer.cuda.to_gpu(x, gpu)\n",
        "\n",
        "# forward calculation of the model by sending X\n",
        "y = infer_model(x)\n",
        "\n",
        "# The result is given as Variable, then we can take a look at the contents by the attribute, .data. \n",
        "y = y.data\n",
        "\n",
        "# send the gpu result to cpu\n",
        "y = chainer.cuda.to_cpu(y)\n",
        "\n",
        "# The most probable number by looking at the argmax\n",
        "pred_label = y.argmax(axis=1)\n",
        "\n",
        "print('predicted label:', pred_label[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 784) -> (1, 1, 1, 784)\n",
            "predicted label: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U39xc46Relir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### より詳細な結果の解析"
      ]
    },
    {
      "metadata": {
        "id": "RfVYvnNVhxfY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### モデルの読み込み"
      ]
    },
    {
      "metadata": {
        "id": "e-d3tuydeVWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "_, test = chainer.datasets.get_mnist()\n",
        "x,t = test._datasets\n",
        "\n",
        "filename=out+'/model' \n",
        "model = MLP(unit, 10)\n",
        "if gpu >= 0:\n",
        "    # Make a specified GPU current\n",
        "    chainer.cuda.get_device_from_id(gpu).use()\n",
        "    model.to_gpu()  # Copy the model to the GPU\n",
        "load_npz(filename, model)\n",
        "\n",
        "x_dnn=np.empty([0, 10])\n",
        "for i in range(0,len(x),batchsize):\n",
        "    x_batch = x[i:i+batchsize]\n",
        "    if gpu >= 0:\n",
        "        x_batch = chainer.Variable(chainer.cuda.to_gpu(x_batch))\n",
        "    x_dnn = np.r_[x_dnn, chainer.cuda.to_cpu(model(x_batch).data)] #model(x_batch).to_cpu().data]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSLcboA7fwOs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線の表示"
      ]
    },
    {
      "metadata": {
        "id": "EuJRc0gqfY3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(out+'/accuracy.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYkXLr0Dfx3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(out+'/loss.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8W4sy7Jkf52D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####ニューラルネットの構造を表示"
      ]
    },
    {
      "metadata": {
        "id": "xzeLraXof2D_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "graph = pydotplus.graphviz.graph_from_dot_file(out+'/cg.dot')\n",
        "graph.write_png(out+'/cg.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-SqcmDc0fcu3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 元の画像をtSNEで二次元に圧縮し表示する\n",
        "\n",
        "・ tSNE はデータ間の距離が保存しつつ次元を削減する次元圧縮法\n",
        "\n",
        "・ この例では画像(28×28次元)を2次元に圧縮して散布図で表示する\n",
        "（各プロットが１枚の画像を表し，色がクラス（数字番号）を示す）\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UeqbkChfe0Cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_tsn= TSNE(n_components=2).fit_transform(x[:1000])\n",
        "plt.scatter(x_tsn[:1000,0], x_tsn[:1000,1],c=t[:1000], alpha=0.5, cmap='tab20c')\n",
        "plt.title('original image 784 (=28 x 28) dim.  -> 2 dim')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsY3qxxofhGF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### DNNの出力（10次元のベクトル）をtSNEで二次元に圧縮し表示する"
      ]
    },
    {
      "metadata": {
        "id": "mCnK7MBSfS0u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_tsn= TSNE(n_components=2).fit_transform(x_dnn[:1000])\n",
        "plt.scatter(x_tsn[:1000,0], x_tsn[:1000,1],c=t[:1000], alpha=0.5, cmap='tab20c')\n",
        "plt.title('DNN output 10 dim.  -> 2 dim')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gAtB5YEzi-Zh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# アニメ画像認識"
      ]
    },
    {
      "metadata": {
        "id": "TsWQuKWvn6Hf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[リンクテキスト](https://qiita.com/mitmul/items/5502ecdd2f0b444c427f) から引用"
      ]
    },
    {
      "metadata": {
        "id": "hym_RdNwjgYJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### データのダウンロード"
      ]
    },
    {
      "metadata": {
        "id": "uEI-gckFi80T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "if [ ! -d animeface-character-dataset ]; then\n",
        "    curl -L -O http://www.nurs.or.jp/~nagadomi/animeface-character-dataset/data/animeface-character-dataset.zip\n",
        "    unzip animeface-character-dataset.zip\n",
        "    rm -rf animeface-character-dataset.zip\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTtbnJzTjWWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls animeface-character-dataset/thumb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "daMZ5V0Qj5xP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### データセットオブジェクトの作成"
      ]
    },
    {
      "metadata": {
        "id": "rH9jDO7VjurT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from itertools import chain\n",
        "from chainer.datasets import LabeledImageDataset\n",
        "\n",
        "\n",
        "# 画像フォルダ\n",
        "IMG_DIR = 'animeface-character-dataset/thumb'\n",
        "\n",
        "# 各キャラクターごとのフォルダ\n",
        "dnames = glob.glob('{}/*'.format(IMG_DIR))\n",
        "\n",
        "# 画像ファイルパス一覧\n",
        "fnames = [glob.glob('{}/*.png'.format(d)) for d in dnames\n",
        "          if not os.path.exists('{}/ignore'.format(d))]\n",
        "fnames = list(chain.from_iterable(fnames))\n",
        "\n",
        "# それぞれにフォルダ名から一意なIDを付与\n",
        "labels = [os.path.basename(os.path.dirname(fn)) for fn in fnames]\n",
        "dnames = [os.path.basename(d) for d in dnames\n",
        "          if not os.path.exists('{}/ignore'.format(d))]\n",
        "labels = [dnames.index(l) for l in labels]\n",
        "\n",
        "\n",
        "# データセット作成\n",
        "d = LabeledImageDataset(list(zip(fnames, labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "klZ06ZTHkBTW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TransformDatasetへの変換。これは、データセットオブジェクトと各データへの変換を表す関数を取るラッパークラスで、これを使うとdata augmentationや前処理などを行う部分をデータセットクラスの外に用意しておくことができる。"
      ]
    },
    {
      "metadata": {
        "id": "PzpNytS8kBf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer.datasets import TransformDataset\n",
        "from PIL import Image\n",
        "\n",
        "width, height = 160, 160\n",
        "\n",
        "# 画像のresize関数\n",
        "def resize(img):\n",
        "    img = Image.fromarray(img.transpose(1, 2, 0))\n",
        "    img = img.resize((width, height), Image.BICUBIC)\n",
        "    return np.asarray(img).transpose(2, 0, 1)\n",
        "\n",
        "# 各データに行う変換\n",
        "def transform(inputs):\n",
        "    img, label = inputs\n",
        "    img = img[:3, ...]\n",
        "    img = resize(img.astype(np.uint8))\n",
        "    img = img - mean[:, None, None]\n",
        "    img = img.astype(np.float32)\n",
        "    # ランダムに左右反転\n",
        "    if np.random.rand() > 0.5:\n",
        "        img = img[..., ::-1]\n",
        "    return img, label\n",
        "\n",
        "# 変換付きデータセットにする\n",
        "td = TransformDataset(d, transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yTl3H-RlJVp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "平均画像の計算"
      ]
    },
    {
      "metadata": {
        "id": "bBkbFjZllJeH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "# 平均画像が未計算なら計算する\n",
        "if not os.path.exists('image_mean.npy'):\n",
        "    # 変換をかまさないバージョンの学習用データセットで平均を計算したい\n",
        "    t, _ = datasets.split_dataset_random(d, int(len(d) * 0.8), seed=0)\n",
        "\n",
        "    mean = np.zeros((3, height, width))\n",
        "    for img, _ in tqdm_notebook(t, desc='Calc mean'):\n",
        "        img = resize(img[:3].astype(np.uint8))\n",
        "        mean += img\n",
        "    mean = mean / float(len(d))\n",
        "    np.save('image_mean', mean)\n",
        "else:\n",
        "    mean = np.load('image_mean.npy')\n",
        "    \n",
        "mean = mean.mean(axis=(1, 2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7xSZHLvGkirU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習用と，検証用データセットに分割．全体の８０％を学習に，残りの２０％を検証用にする"
      ]
    },
    {
      "metadata": {
        "id": "KzaIoJWtkB5U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer import datasets\n",
        "\n",
        "train, valid = datasets.split_dataset_random(td, int(len(d) * 0.8), seed=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5rchS9Uk1TY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### モデルの構築"
      ]
    },
    {
      "metadata": {
        "id": "eDBY5zrtliw0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####学習済みモデルのダウンロード"
      ]
    },
    {
      "metadata": {
        "id": "CC2ST6rukqHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8fef357f-72b3-4cf5-839e-80e17747828c"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "if [ ! -f illust2vec_ver200.caffemodel ]; then\n",
        "    curl -L -O https://github.com/rezoo/illustration2vec/releases/download/v2.0.0/illust2vec_ver200.caffemodel\n",
        "fi"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   618    0   618    0     0   2746      0 --:--:-- --:--:-- --:--:--  2746\n",
            "\r  0  933M    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  1  933M    1 13.2M    0     0  9090k      0  0:01:45  0:00:01  0:01:44 15.9M\r  5  933M    5 49.0M    0     0  19.3M      0  0:00:48  0:00:02  0:00:46 26.2M\r  8  933M    8 76.1M    0     0  21.0M      0  0:00:44  0:00:03  0:00:41 25.7M\r  9  933M    9 89.4M    0     0  19.8M      0  0:00:47  0:00:04  0:00:43 23.2M\r 11  933M   11  104M    0     0  18.9M      0  0:00:49  0:00:05  0:00:44 21.5M\r 12  933M   12  118M    0     0  18.1M      0  0:00:51  0:00:06  0:00:45 20.9M\r 14  933M   14  133M    0     0  17.7M      0  0:00:52  0:00:07  0:00:45 16.9M\r 15  933M   15  148M    0     0  17.5M      0  0:00:53  0:00:08  0:00:45 14.8M\r 17  933M   17  164M    0     0  17.2M      0  0:00:54  0:00:09  0:00:45 14.9M\r 19  933M   19  180M    0     0  17.1M      0  0:00:54  0:00:10  0:00:44 15.1M\r 20  933M   20  195M    0     0  17.0M      0  0:00:54  0:00:11  0:00:43 15.5M\r 22  933M   22  211M    0     0  16.8M      0  0:00:55  0:00:12  0:00:43 15.5M\r 24  933M   24  227M    0     0  16.8M      0  0:00:55  0:00:13  0:00:42 15.6M\r 26  933M   26  243M    0     0  16.7M      0  0:00:55  0:00:14  0:00:41 15.8M\r 27  933M   27  256M    0     0  16.4M      0  0:00:56  0:00:15  0:00:41 15.1M\r 28  933M   28  268M    0     0  16.2M      0  0:00:57  0:00:16  0:00:41 14.5M\r 30  933M   30  282M    0     0  16.1M      0  0:00:57  0:00:17  0:00:40 14.2M\r 31  933M   31  297M    0     0  16.0M      0  0:00:58  0:00:18  0:00:40 14.0M\r 33  933M   33  312M    0     0  16.0M      0  0:00:58  0:00:19  0:00:39 13.8M\r 35  933M   35  328M    0     0  16.0M      0  0:00:58  0:00:20  0:00:38 14.5M\r 36  933M   36  344M    0     0  16.0M      0  0:00:58  0:00:21  0:00:37 15.1M\r 38  933M   38  360M    0     0  16.0M      0  0:00:58  0:00:22  0:00:36 15.4M\r 40  933M   40  376M    0     0  16.0M      0  0:00:58  0:00:23  0:00:35 15.7M\r 42  933M   42  392M    0     0  16.0M      0  0:00:58  0:00:24  0:00:34 15.9M\r 43  933M   43  408M    0     0  16.0M      0  0:00:58  0:00:25  0:00:33 15.9M\r 45  933M   45  423M    0     0  15.9M      0  0:00:58  0:00:26  0:00:32 15.9M\r 47  933M   47  440M    0     0  16.0M      0  0:00:58  0:00:27  0:00:31 16.0M\r 48  933M   48  457M    0     0  16.0M      0  0:00:58  0:00:28  0:00:30 16.1M\r 50  933M   50  473M    0     0  16.0M      0  0:00:58  0:00:29  0:00:29 16.2M\r 52  933M   52  491M    0     0  16.1M      0  0:00:57  0:00:30  0:00:27 16.6M\r 54  933M   54  510M    0     0  16.2M      0  0:00:57  0:00:31  0:00:26 17.3M\r 56  933M   56  529M    0     0  16.3M      0  0:00:57  0:00:32  0:00:25 17.9M\r 59  933M   59  551M    0     0  16.4M      0  0:00:56  0:00:33  0:00:23 18.9M\r 61  933M   61  575M    0     0  16.6M      0  0:00:55  0:00:34  0:00:21 20.2M\r 64  933M   64  600M    0     0  16.9M      0  0:00:55  0:00:35  0:00:20 21.8M\r 67  933M   67  629M    0     0  17.2M      0  0:00:54  0:00:36  0:00:18 23.8M\r 70  933M   70  662M    0     0  17.6M      0  0:00:52  0:00:37  0:00:15 26.3M\r 74  933M   74  696M    0     0  18.0M      0  0:00:51  0:00:38  0:00:13 29.0M\r 78  933M   78  734M    0     0  18.5M      0  0:00:50  0:00:39  0:00:11 31.9M\r 82  933M   82  771M    0     0  19.0M      0  0:00:49  0:00:40  0:00:09 33.9M\r 86  933M   86  807M    0     0  19.4M      0  0:00:48  0:00:41  0:00:07 35.3M\r 90  933M   90  843M    0     0  19.8M      0  0:00:47  0:00:42  0:00:05 36.4M\r 94  933M   94  879M    0     0  20.2M      0  0:00:46  0:00:43  0:00:03 36.5M\r 98  933M   98  916M    0     0  20.5M      0  0:00:45  0:00:44  0:00:01 36.3M\r100  933M  100  933M    0     0  20.7M      0  0:00:44  0:00:44 --:--:-- 36.6M\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JDGMrAspmNOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "d3809d22-c572-430f-a481-b64c9a784ec7"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install chainer\n",
        "pip install cupy-cuda80 # or cupy-cuda90 or cupy-cuda91\n",
        "pip install Pillow\n",
        "pip install tqdm"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chainer in /usr/local/lib/python3.6/dist-packages (5.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer) (3.0.10)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.14.6)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer) (40.6.2)\n",
            "Collecting cupy-cuda80\n",
            "  Downloading https://files.pythonhosted.org/packages/38/b9/a0b69902a484e7da417cb9b49674e2a52439b288cd59656115520534e9aa/cupy_cuda80-5.1.0-cp36-cp36m-manylinux1_x86_64.whl (201.6MB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.11.0)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (0.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.14.6)\n",
            "Installing collected packages: cupy-cuda80\n",
            "Successfully installed cupy-cuda80-5.1.0\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Te8BjXdlfoD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### モデルの定義"
      ]
    },
    {
      "metadata": {
        "id": "eAFijUGwlfyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7a627457-9899-49bb-879c-585419e8fe8b"
      },
      "cell_type": "code",
      "source": [
        "import dill\n",
        "\n",
        "import chainer\n",
        "import chainer.links as L\n",
        "import chainer.functions as F\n",
        "\n",
        "from chainer import Chain\n",
        "from chainer.links.caffe import CaffeFunction\n",
        "from chainer import serializers\n",
        "\n",
        "class Illust2Vec(Chain):\n",
        "\n",
        "    CAFFEMODEL_FN = 'illust2vec_ver200.caffemodel'\n",
        "\n",
        "    def __init__(self, n_classes, unchain=True):\n",
        "        w = chainer.initializers.HeNormal()        \n",
        "        model = CaffeFunction(self.CAFFEMODEL_FN)  # CaffeModelを読み込んで保存します。（時間がかかります）\n",
        "        del model.encode1  # メモリ節約のため不要なレイヤを削除します。\n",
        "        del model.encode2\n",
        "        del model.forwards['encode1']\n",
        "        del model.forwards['encode2']\n",
        "        model.layers = model.layers[:-2]\n",
        "\n",
        "        super(Illust2Vec, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.trunk = model  # 元のIllust2Vecモデルをtrunkとしてこのモデルに含めます。\n",
        "            self.fc7 = L.Linear(None, 4096, initialW=w)\n",
        "            self.bn7 = L.BatchNormalization(4096)\n",
        "            self.fc8 = L.Linear(4096, n_classes, initialW=w)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = self.trunk({'data': x}, ['conv6_3'])[0]  # 元のIllust2Vecモデルのconv6_3の出力を取り出します。\n",
        "        h.unchain_backward()\n",
        "        h = F.dropout(F.relu(self.bn7(self.fc7(h))))  # ここ以降は新しく追加した層です。\n",
        "        return self.fc8(h)\n",
        "\n",
        "n_classes = len(dnames)\n",
        "model = Illust2Vec(n_classes)\n",
        "model = L.Classifier(model)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/chainer/links/caffe/caffe_function.py:166: UserWarning: Skip the layer \"encode1neuron\", since CaffeFunction does notsupport Sigmoid layer\n",
            "  'support %s layer' % (layer.name, layer.type))\n",
            "/usr/local/lib/python3.6/dist-packages/chainer/links/caffe/caffe_function.py:166: UserWarning: Skip the layer \"loss\", since CaffeFunction does notsupport SigmoidCrossEntropyLoss layer\n",
            "  'support %s layer' % (layer.name, layer.type))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ISmRMDPnESc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習のスタート"
      ]
    },
    {
      "metadata": {
        "id": "DKjAjYZyk14p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a7034c44-aa22-4de5-cf12-22ed772f6114"
      },
      "cell_type": "code",
      "source": [
        "if gpu_id >= 0:\n",
        "  # Make a specified GPU current\n",
        "  chainer.cuda.get_device_from_id(gpu_id).use()\n",
        "  model.to_gpu() \n",
        "  \n",
        "train_iter = iterators.MultiprocessIterator(train, batchsize)\n",
        "valid_iter = iterators.MultiprocessIterator(\n",
        "    valid, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "optimizer = optimizers.MomentumSGD(lr=initial_lr)\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n",
        "\n",
        "updater = training.StandardUpdater(\n",
        "    train_iter, optimizer, device=gpu_id)\n",
        "\n",
        "trainer = training.Trainer(updater, (train_epoch, 'epoch'), out='AnimeFace-result')\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.observe_lr())\n",
        "\n",
        "# 標準出力に書き出したい値\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch',\n",
        "     'main/loss',\n",
        "     'main/accuracy',\n",
        "     'val/main/loss',\n",
        "     'val/main/accuracy',\n",
        "     'elapsed_time',\n",
        "     'lr']))\n",
        "\n",
        "# ロスのプロットを毎エポック自動的に保存\n",
        "trainer.extend(extensions.PlotReport(\n",
        "        ['main/loss',\n",
        "         'val/main/loss'],\n",
        "        'epoch', file_name='loss.png'))\n",
        "\n",
        "# 精度のプロットも毎エポック自動的に保存\n",
        "trainer.extend(extensions.PlotReport(\n",
        "        ['main/accuracy',\n",
        "         'val/main/accuracy'],\n",
        "        'epoch', file_name='accuracy.png'))\n",
        "\n",
        "# モデルのtrainプロパティをFalseに設定してvalidationするextension\n",
        "trainer.extend(extensions.Evaluator(valid_iter, model, device=gpu_id), name='val')\n",
        "\n",
        "# 指定したエポックごとに学習率をlr_drop_ratio倍にする\n",
        "trainer.extend(\n",
        "    extensions.ExponentialShift('lr', lr_drop_ratio),\n",
        "    trigger=(lr_drop_epoch, 'epoch'))\n",
        "\n",
        "trainer.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time  lr        \n",
            "\u001b[J1           0.604268    0.831126       0.543726       0.855123           77.6659       0.01        \n",
            "\u001b[J2           0.421601    0.876759       0.479643       0.866374           155.428       0.01        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Z5Ank1GnrV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 結果の解析"
      ]
    },
    {
      "metadata": {
        "id": "AbUEP2NYnuyy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線の表示"
      ]
    },
    {
      "metadata": {
        "id": "5Kp-37nRnhrb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='AnimeFace-result/loss.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUqpyvCtlBl4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image(filename='AnimeFace-result/accuracy.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1inM1C8nnD9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 検証セットに対する識別結果の表示"
      ]
    },
    {
      "metadata": {
        "id": "ikhMLIyGnkmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from chainer import cuda\n",
        "\n",
        "chainer.config.train = False\n",
        "for _ in range(10):\n",
        "    x, t = valid[np.random.randint(len(valid))]\n",
        "    x = cuda.to_gpu(x)\n",
        "    y = F.softmax(model.predictor(x[None, ...]))\n",
        "\n",
        "    pred = os.path.basename(dnames[int(y.data.argmax())])\n",
        "    label = os.path.basename(dnames[t])\n",
        "\n",
        "    print('pred:', pred, 'label:', label, pred == label)\n",
        "\n",
        "    x = cuda.to_cpu(x)\n",
        "    x += mean[:, None, None]\n",
        "    x = x / 256\n",
        "    x = np.clip(x, 0, 1)\n",
        "    plt.imshow(x.transpose(1, 2, 0))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}