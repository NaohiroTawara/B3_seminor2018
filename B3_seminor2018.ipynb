{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B3_seminor2018.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "eSLcboA7fwOs",
        "-SqcmDc0fcu3",
        "JsY3qxxofhGF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaohiroTawara/B3_seminor2018/blob/master/B3_seminor2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MgNHooNSNV1i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Colaboratory（Google Colab）とは"
      ]
    },
    {
      "metadata": {
        "id": "ZHGxM1fRNNL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "・ Google Colabは、完全にクラウドで実行される Jupyter ノートブック環境です．\n",
        "\n",
        "・感覚的には，クラウド上のバーチャル環境を割り当てられ，無料で使えるイメージです"
      ]
    },
    {
      "metadata": {
        "id": "C9Ad6HEhZmv-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 注意事項\n",
        "\n",
        "\n",
        "\n",
        "### ９０分ルール，１２時間ルール\n",
        "\n",
        " \n",
        "*   計算途中でこのページを離れても計算は継続されますが，ページから離れたまま９０分が経過すると計算が強制的に止まります．そのため９０分以上かかる計算を行う場合はブラウザを閉じないようにしてください\n",
        "\n",
        "*   ページから離れるかにかかわらず，起動時から１２時間が経過するとすべての環境がリセットされます．そのため１２時間以上計算がかかる場合はこのスクリプトは適用できません．\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "95FbEFpYN9mh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 使い方"
      ]
    },
    {
      "metadata": {
        "id": "m6PUwAFbOHq3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "挿入ー＞コードセルを選択するとコードを打ち込み，実行可能なセルが追加されます.\n",
        "\n",
        "コードセルはpython のコマンドの他に，!マークを先頭につけることで仮想環境のbashコマンドを実行することができます\n",
        "\n",
        "コマンド入力後にセルの左にある▶を押すとコードが実行されます\n"
      ]
    },
    {
      "metadata": {
        "id": "-T6iNY7xOOD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a=1\n",
        "b=2\n",
        "print(\"a + b = {}\".format(a+b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h19eAurvO5Pc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls # カレントディレクトリ内の一覧を見るコマンド"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niexkbOXO7lD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /etc/lsb-release #Linux のバージョンを調べるコマンド"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8JnwkMQPInn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!free -h # メモリを調べるコマンド"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ps7wvXtIPMVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo | grep -e \"model name\" -e \"processor\" #cpuの型番を調べるコマンド"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxWye7s8NEa1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GPUの割当"
      ]
    },
    {
      "metadata": {
        "id": "ADNmC9lnNZxA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ランタイムー＞ランタイムのタイプを変更\n",
        "\n",
        "ハードウェアアクセラレータをGPUに変更"
      ]
    },
    {
      "metadata": {
        "id": "tI_pWLIJPwwm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#matplotlibによる可視化の例"
      ]
    },
    {
      "metadata": {
        "id": "JaB2e1PMQEie",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.arange(20)\n",
        "y = [x_i + np.random.randn(1) for x_i in x]\n",
        "a, b = np.polyfit(x, y, 1)\n",
        "_ = plt.plot(x, y, 'o', np.arange(20), a*np.arange(20)+b, '-')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VobS2p59Wnlt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "-BeXhLf_Womb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# chainer によるDNN構築"
      ]
    },
    {
      "metadata": {
        "id": "xcO3TCGpWrGL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## chainer のインストール\n",
        "・chainerはデフォルトでは google colabで使えないので，仮想環境にインストールする必要があります "
      ]
    },
    {
      "metadata": {
        "id": "zf79Ykp_QE_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install https://github.com/kmaehashi/chainer-colab/releases/download/2018-02-06/cupy_cuda80-4.0.0b3-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install 'chainer==4.0.0b3'\n",
        "!apt-get install graphviz\n",
        "!pip install 'chaineripy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EgRklEXMXBi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "26dabf78-7b8d-4f27-fda1-78bfa2d86040"
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "#gpu が使えるかチェック\n",
        "print('GPU availability:', chainer.cuda.available)\n",
        "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU availability: True\n",
            "cuDNN availablility: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2unYeu8TXyEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST数字文字認識"
      ]
    },
    {
      "metadata": {
        "id": "cLqqh16lbn23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習データの用意"
      ]
    },
    {
      "metadata": {
        "id": "4nqv356Jbk28",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer.datasets import mnist\n",
        "# set matplotlib so that we can see our drawing inside this notebook\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download the MNIST data if you haven't downloaded it yet\n",
        "train, test = mnist.get_mnist(withlabel=True, ndim=1)\n",
        "# Display an example from the MNIST dataset.\n",
        "# `x` contains the input image array and `t` contains that target class\n",
        "# label as an integer.\n",
        "plt.figure()\n",
        "for i in range(1,11):\n",
        "  x, t = train[i]\n",
        "  plt.subplot(2,5,i)\n",
        "  plt.imshow(x.reshape(28, 28), cmap='gray')\n",
        "  plt.title('label: {}'.format(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHcPMXnLgPD2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 必要なパッケージのインポート"
      ]
    },
    {
      "metadata": {
        "id": "o57pg4ASgRN8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "from chainer.serializers import save_npz, load_npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zMd5ZeaJaYr2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ネットワーク構造の定義"
      ]
    },
    {
      "metadata": {
        "id": "37BSllOEXzbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network definition\n",
        "class MLP(chainer.Chain):\n",
        "\n",
        "    def __init__(self, n_units, n_out):\n",
        "        super(MLP, self).__init__()\n",
        "        with self.init_scope():\n",
        "            # the size of the inputs to each layer will be inferred\n",
        "            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n",
        "            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n",
        "            self.l3 = L.Linear(None, n_out)  # n_units -> n_out\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h1 = F.relu(self.l1(x))\n",
        "        h2 = F.relu(self.l2(h1))\n",
        "        return self.l3(h2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTirXJNoadOZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ネットワークの学習"
      ]
    },
    {
      "metadata": {
        "id": "vtjMh9heZBRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gpu = 0 #gpu id (CPUを使う場合は-1)\n",
        "unit = 100 # 中間層のノード数\n",
        "batchsize =128 # ミニバッチサイズ\n",
        "epoch =20 # エポック数\n",
        "out = 'results' # 結果の出力先\n",
        "frequency=-1 # 学習経過の出力タイミング -1の場合エポックごと\n",
        "    \n",
        "# Set up a neural network to train\n",
        "# Classifier reports softmax cross entropy loss and accuracy at every\n",
        "# iteration, which will be used by the PrintReport extension below.\n",
        "mlp = MLP(unit, 10)\n",
        "model = L.Classifier(mlp)\n",
        "if gpu >= 0:\n",
        "  # Make a specified GPU current\n",
        "  chainer.cuda.get_device_from_id(gpu).use()\n",
        "  model.to_gpu()  # GPU にコピー\n",
        "\n",
        "# 最適化法の選択\n",
        "optimizer = chainer.optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "# MNIST datasetの取得\n",
        "train, test = chainer.datasets.get_mnist()\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "test_iter = chainer.iterators.SerialIterator(test, batchsize,\n",
        "                                               repeat=False, shuffle=False)\n",
        "\n",
        "# Set up a trainer\n",
        "updater = training.StandardUpdater(train_iter, optimizer, device=gpu)\n",
        "trainer = training.Trainer(updater, (epoch, 'epoch'), out=out)\n",
        "\n",
        "# Evaluate the model with the test dataset for each epoch\n",
        "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu))\n",
        "\n",
        "# Dump a computational graph from 'loss' variable at the first iteration\n",
        "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
        "trainer.extend(extensions.dump_graph('main/loss'))\n",
        "\n",
        "# Take a snapshot for each specified epoch\n",
        "frequency = epoch if frequency == -1 else max(1, frequency)\n",
        "trainer.extend(extensions.snapshot(), trigger=(frequency, 'epoch'))\n",
        "\n",
        "# Write a log of evaluation statistics for each epoch\n",
        "trainer.extend(extensions.LogReport())\n",
        "\n",
        "# Save two plot images to the result dir\n",
        "if extensions.PlotReport.available():\n",
        "  trainer.extend(\n",
        "      extensions.PlotReport(['main/loss', 'validation/main/loss'],\n",
        "                            'epoch', file_name='loss.png'))\n",
        "  trainer.extend(\n",
        "      extensions.PlotReport(\n",
        "          ['main/accuracy', 'validation/main/accuracy'],\n",
        "          'epoch', file_name='accuracy.png'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch', 'main/loss', 'validation/main/loss',\n",
        "     'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
        "\n",
        "# Print a progress bar to stdout\n",
        "#trainer.extend(extensions.ProgressBar())\n",
        "\n",
        "# Run the training\n",
        "trainer.run()\n",
        "\n",
        "# Save the trained model\n",
        "save_npz(out+'/model', mlp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1ZYqSAbcjKT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習したモデルを用いてテストデータを識別してみる"
      ]
    },
    {
      "metadata": {
        "id": "ya2aHvxrYyBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the infrence (evaluation) model as the previous model\n",
        "infer_model = MLP(unit, 10)\n",
        "\n",
        "# Load the saved parameters into the parameters of the new inference model to overwrite \n",
        "load_npz(out+'/model', infer_model)\n",
        "\n",
        "# Send the model to utilize GPU by to_GPU\n",
        "if gpu >= 0:\n",
        "    infer_model.to_gpu(gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1vIKLRnccqLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get a test image and label\n",
        "x, t = test[0]\n",
        "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
        "plt.show()\n",
        "print('label:', t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I8PcTw38dB6R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6626f621-d000-4a25-965a-53ef802fa5d2"
      },
      "cell_type": "code",
      "source": [
        "# change the shape to minibutch. \n",
        "# In this example, the size of minibatch is 1. \n",
        "# Inference using any mini-batch size can be performed.\n",
        "\n",
        "print(x.shape, end=' -> ')\n",
        "x = x[None, ...]\n",
        "print(x.shape)\n",
        "\n",
        "# to calculate by GPU, send the data to GPU, too. \n",
        "if gpu >= 0:\n",
        "    x = chainer.cuda.to_gpu(x, gpu)\n",
        "\n",
        "# forward calculation of the model by sending X\n",
        "y = infer_model(x)\n",
        "\n",
        "# The result is given as Variable, then we can take a look at the contents by the attribute, .data. \n",
        "y = y.data\n",
        "\n",
        "# send the gpu result to cpu\n",
        "y = chainer.cuda.to_cpu(y)\n",
        "\n",
        "# The most probable number by looking at the argmax\n",
        "pred_label = y.argmax(axis=1)\n",
        "\n",
        "print('predicted label:', pred_label[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 784) -> (1, 1, 1, 784)\n",
            "predicted label: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U39xc46Relir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### より詳細な結果の解析"
      ]
    },
    {
      "metadata": {
        "id": "RfVYvnNVhxfY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### モデルの読み込み"
      ]
    },
    {
      "metadata": {
        "id": "e-d3tuydeVWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "_, test = chainer.datasets.get_mnist()\n",
        "x,t = test._datasets\n",
        "\n",
        "filename=out+'/model' \n",
        "model = MLP(unit, 10)\n",
        "if gpu >= 0:\n",
        "    # Make a specified GPU current\n",
        "    chainer.cuda.get_device_from_id(gpu).use()\n",
        "    model.to_gpu()  # Copy the model to the GPU\n",
        "load_npz(filename, model)\n",
        "\n",
        "x_dnn=np.empty([0, 10])\n",
        "for i in range(0,len(x),batchsize):\n",
        "    x_batch = x[i:i+batchsize]\n",
        "    if gpu >= 0:\n",
        "        x_batch = chainer.Variable(chainer.cuda.to_gpu(x_batch))\n",
        "    x_dnn = np.r_[x_dnn, chainer.cuda.to_cpu(model(x_batch).data)] #model(x_batch).to_cpu().data]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSLcboA7fwOs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線の表示"
      ]
    },
    {
      "metadata": {
        "id": "EuJRc0gqfY3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(out+'/accuracy.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYkXLr0Dfx3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(out+'/loss.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8W4sy7Jkf52D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####ニューラルネットの構造を表示"
      ]
    },
    {
      "metadata": {
        "id": "xzeLraXof2D_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "graph = pydotplus.graphviz.graph_from_dot_file(out+'/cg.dot')\n",
        "graph.write_png(out+'/cg.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-SqcmDc0fcu3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 元の画像をtSNEで二次元に圧縮し表示する\n",
        "\n",
        "・ tSNE はデータ間の距離が保存しつつ次元を削減する次元圧縮法\n",
        "\n",
        "・ この例では画像(28×28次元)を2次元に圧縮して散布図で表示する\n",
        "（各プロットが１枚の画像を表し，色がクラス（数字番号）を示す）\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UeqbkChfe0Cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_tsn= TSNE(n_components=2).fit_transform(x[:1000])\n",
        "plt.scatter(x_tsn[:1000,0], x_tsn[:1000,1],c=t[:1000], alpha=0.5, cmap='tab20c')\n",
        "plt.title('original image 784 (=28 x 28) dim.  -> 2 dim')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsY3qxxofhGF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### DNNの出力（10次元のベクトル）をtSNEで二次元に圧縮し表示する"
      ]
    },
    {
      "metadata": {
        "id": "mCnK7MBSfS0u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_tsn= TSNE(n_components=2).fit_transform(x_dnn[:1000])\n",
        "plt.scatter(x_tsn[:1000,0], x_tsn[:1000,1],c=t[:1000], alpha=0.5, cmap='tab20c')\n",
        "plt.title('DNN output 10 dim.  -> 2 dim')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gAtB5YEzi-Zh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# アニメ画像認識"
      ]
    },
    {
      "metadata": {
        "id": "TsWQuKWvn6Hf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[リンクテキスト](https://qiita.com/mitmul/items/5502ecdd2f0b444c427f) から引用"
      ]
    },
    {
      "metadata": {
        "id": "hym_RdNwjgYJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### データのダウンロード"
      ]
    },
    {
      "metadata": {
        "id": "uEI-gckFi80T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "if [ ! -d animeface-character-dataset ]; then\n",
        "    curl -L -O http://www.nurs.or.jp/~nagadomi/animeface-character-dataset/data/animeface-character-dataset.zip\n",
        "    unzip animeface-character-dataset.zip\n",
        "    rm -rf animeface-character-dataset.zip\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTtbnJzTjWWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls animeface-character-dataset/thumb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "daMZ5V0Qj5xP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### データセットオブジェクトの作成"
      ]
    },
    {
      "metadata": {
        "id": "rH9jDO7VjurT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from itertools import chain\n",
        "from chainer.datasets import LabeledImageDataset\n",
        "\n",
        "\n",
        "# 画像フォルダ\n",
        "IMG_DIR = 'animeface-character-dataset/thumb'\n",
        "\n",
        "# 各キャラクターごとのフォルダ\n",
        "dnames = glob.glob('{}/*'.format(IMG_DIR))\n",
        "\n",
        "# 画像ファイルパス一覧\n",
        "fnames = [glob.glob('{}/*.png'.format(d)) for d in dnames\n",
        "          if not os.path.exists('{}/ignore'.format(d))]\n",
        "fnames = list(chain.from_iterable(fnames))\n",
        "\n",
        "# それぞれにフォルダ名から一意なIDを付与\n",
        "labels = [os.path.basename(os.path.dirname(fn)) for fn in fnames]\n",
        "dnames = [os.path.basename(d) for d in dnames\n",
        "          if not os.path.exists('{}/ignore'.format(d))]\n",
        "labels = [dnames.index(l) for l in labels]\n",
        "\n",
        "\n",
        "# データセット作成\n",
        "d = LabeledImageDataset(list(zip(fnames, labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "klZ06ZTHkBTW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TransformDatasetへの変換。これは、データセットオブジェクトと各データへの変換を表す関数を取るラッパークラスで、これを使うとdata augmentationや前処理などを行う部分をデータセットクラスの外に用意しておくことができる。"
      ]
    },
    {
      "metadata": {
        "id": "PzpNytS8kBf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer.datasets import TransformDataset\n",
        "from PIL import Image\n",
        "\n",
        "width, height = 160, 160\n",
        "\n",
        "# 画像のresize関数\n",
        "def resize(img):\n",
        "    img = Image.fromarray(img.transpose(1, 2, 0))\n",
        "    img = img.resize((width, height), Image.BICUBIC)\n",
        "    return np.asarray(img).transpose(2, 0, 1)\n",
        "\n",
        "# 各データに行う変換\n",
        "def transform(inputs):\n",
        "    img, label = inputs\n",
        "    img = img[:3, ...]\n",
        "    img = resize(img.astype(np.uint8))\n",
        "    img = img - mean[:, None, None]\n",
        "    img = img.astype(np.float32)\n",
        "    # ランダムに左右反転\n",
        "    if np.random.rand() > 0.5:\n",
        "        img = img[..., ::-1]\n",
        "    return img, label\n",
        "\n",
        "# 変換付きデータセットにする\n",
        "td = TransformDataset(d, transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yTl3H-RlJVp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "平均画像の計算"
      ]
    },
    {
      "metadata": {
        "id": "bBkbFjZllJeH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "# 平均画像が未計算なら計算する\n",
        "if not os.path.exists('image_mean.npy'):\n",
        "    # 変換をかまさないバージョンの学習用データセットで平均を計算したい\n",
        "    t, _ = datasets.split_dataset_random(d, int(len(d) * 0.8), seed=0)\n",
        "\n",
        "    mean = np.zeros((3, height, width))\n",
        "    for img, _ in tqdm_notebook(t, desc='Calc mean'):\n",
        "        img = resize(img[:3].astype(np.uint8))\n",
        "        mean += img\n",
        "    mean = mean / float(len(d))\n",
        "    np.save('image_mean', mean)\n",
        "else:\n",
        "    mean = np.load('image_mean.npy')\n",
        "    \n",
        "mean = mean.mean(axis=(1, 2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7xSZHLvGkirU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習用と，検証用データセットに分割．全体の８０％を学習に，残りの２０％を検証用にする"
      ]
    },
    {
      "metadata": {
        "id": "KzaIoJWtkB5U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer import datasets\n",
        "\n",
        "train, valid = datasets.split_dataset_random(td, int(len(d) * 0.8), seed=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5rchS9Uk1TY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### モデルの構築"
      ]
    },
    {
      "metadata": {
        "id": "eDBY5zrtliw0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####学習済みモデルのダウンロード"
      ]
    },
    {
      "metadata": {
        "id": "CC2ST6rukqHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "if [ ! -f illust2vec_ver200.caffemodel ]; then\n",
        "    curl -L -O https://github.com/rezoo/illustration2vec/releases/download/v2.0.0/illust2vec_ver200.caffemodel\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JDGMrAspmNOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install Pillow\n",
        "pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Te8BjXdlfoD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### モデルの定義"
      ]
    },
    {
      "metadata": {
        "id": "eAFijUGwlfyt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import dill\n",
        "\n",
        "import chainer\n",
        "import chainer.links as L\n",
        "import chainer.functions as F\n",
        "\n",
        "from chainer import Chain\n",
        "from chainer.links.caffe import CaffeFunction\n",
        "from chainer import serializers\n",
        "\n",
        "class Illust2Vec(Chain):\n",
        "\n",
        "    CAFFEMODEL_FN = 'illust2vec_ver200.caffemodel'\n",
        "\n",
        "    def __init__(self, n_classes, unchain=True):\n",
        "        w = chainer.initializers.HeNormal()        \n",
        "        model = CaffeFunction(self.CAFFEMODEL_FN)  # CaffeModelを読み込んで保存します。（時間がかかります）\n",
        "        del model.encode1  # メモリ節約のため不要なレイヤを削除します。\n",
        "        del model.encode2\n",
        "        del model.forwards['encode1']\n",
        "        del model.forwards['encode2']\n",
        "        model.layers = model.layers[:-2]\n",
        "\n",
        "        super(Illust2Vec, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.trunk = model  # 元のIllust2Vecモデルをtrunkとしてこのモデルに含めます。\n",
        "            self.fc7 = L.Linear(None, 4096, initialW=w)\n",
        "            self.bn7 = L.BatchNormalization(4096)\n",
        "            self.fc8 = L.Linear(4096, n_classes, initialW=w)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = self.trunk({'data': x}, ['conv6_3'])[0]  # 元のIllust2Vecモデルのconv6_3の出力を取り出します。\n",
        "        h.unchain_backward()\n",
        "        h = F.dropout(F.relu(self.bn7(self.fc7(h))))  # ここ以降は新しく追加した層です。\n",
        "        return self.fc8(h)\n",
        "\n",
        "n_classes = len(dnames)\n",
        "model = Illust2Vec(n_classes)\n",
        "model = L.Classifier(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ISmRMDPnESc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習のスタート"
      ]
    },
    {
      "metadata": {
        "id": "DKjAjYZyk14p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchsize = 64\n",
        "gpu_id = 0\n",
        "initial_lr = 0.01\n",
        "lr_drop_epoch = 10\n",
        "lr_drop_ratio = 0.1\n",
        "train_epoch = 20\n",
        "\n",
        "if gpu_id >= 0:\n",
        "  # Make a specified GPU current\n",
        "  chainer.cuda.get_device_from_id(gpu_id).use()\n",
        "  model.to_gpu() \n",
        "  \n",
        "train_iter = iterators.MultiprocessIterator(train, batchsize)\n",
        "valid_iter = iterators.MultiprocessIterator(\n",
        "    valid, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "optimizer = optimizers.MomentumSGD(lr=initial_lr)\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n",
        "\n",
        "updater = training.StandardUpdater(\n",
        "    train_iter, optimizer, device=gpu_id)\n",
        "\n",
        "trainer = training.Trainer(updater, (train_epoch, 'epoch'), out='AnimeFace-result')\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.observe_lr())\n",
        "\n",
        "# 標準出力に書き出したい値\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch',\n",
        "     'main/loss',\n",
        "     'main/accuracy',\n",
        "     'val/main/loss',\n",
        "     'val/main/accuracy',\n",
        "     'elapsed_time',\n",
        "     'lr']))\n",
        "\n",
        "# ロスのプロットを毎エポック自動的に保存\n",
        "trainer.extend(extensions.PlotReport(\n",
        "        ['main/loss',\n",
        "         'val/main/loss'],\n",
        "        'epoch', file_name='loss.png'))\n",
        "\n",
        "# 精度のプロットも毎エポック自動的に保存\n",
        "trainer.extend(extensions.PlotReport(\n",
        "        ['main/accuracy',\n",
        "         'val/main/accuracy'],\n",
        "        'epoch', file_name='accuracy.png'))\n",
        "\n",
        "# モデルのtrainプロパティをFalseに設定してvalidationするextension\n",
        "trainer.extend(extensions.Evaluator(valid_iter, model, device=gpu_id), name='val')\n",
        "\n",
        "# 指定したエポックごとに学習率をlr_drop_ratio倍にする\n",
        "trainer.extend(\n",
        "    extensions.ExponentialShift('lr', lr_drop_ratio),\n",
        "    trigger=(lr_drop_epoch, 'epoch'))\n",
        "\n",
        "trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Z5Ank1GnrV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 結果の解析"
      ]
    },
    {
      "metadata": {
        "id": "AbUEP2NYnuyy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 学習曲線の表示"
      ]
    },
    {
      "metadata": {
        "id": "5Kp-37nRnhrb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='AnimeFace-result/loss.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUqpyvCtlBl4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image(filename='AnimeFace-result/accuracy.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1inM1C8nnD9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 検証セットに対する識別結果の表示"
      ]
    },
    {
      "metadata": {
        "id": "ikhMLIyGnkmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from chainer import cuda\n",
        "\n",
        "chainer.config.train = False\n",
        "for _ in range(10):\n",
        "    x, t = valid[np.random.randint(len(valid))]\n",
        "    x = cuda.to_gpu(x)\n",
        "    y = F.softmax(model.predictor(x[None, ...]))\n",
        "\n",
        "    pred = os.path.basename(dnames[int(y.data.argmax())])\n",
        "    label = os.path.basename(dnames[t])\n",
        "\n",
        "    print('pred:', pred, 'label:', label, pred == label)\n",
        "\n",
        "    x = cuda.to_cpu(x)\n",
        "    x += mean[:, None, None]\n",
        "    x = x / 256\n",
        "    x = np.clip(x, 0, 1)\n",
        "    plt.imshow(x.transpose(1, 2, 0))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y68yZN1Vr9GM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}